---
date: 2025-07-03
title: "Plateforme de donn√©es - Partie 2 : Tout automatiser ü§ñ"
sidebar: auto
author: Martin Erpicum
category: Article
tags:
  - data
  - orchestrator
---

_R√©sum√© ex√©cutif_ : Dans une organisation polyc√©phale, la Gouvernance des Donn√©es est un d√©fi complexe. Cet article explore la mise en ≈ìuvre d'une Plateforme de Donn√©es bas√©e sur [Dagster](https://dagster.io/) pour la [F√©d√©ration Wallonie-Bruxelles (FWB)](https://www.federation-wallonie-bruxelles.be). Il met en √©vidence l'importance de l'automatisation, de la modularit√© et de la r√©utilisabilit√© des composants pour abaisser la barri√®re technique et am√©liorer la litt√©ratie des donn√©es parmi les analystes de donn√©es et les gestionnaires de donn√©es.

---

_Les opinions exprim√©es sur ce site web sont les miennes et ne refl√®tent pas n√©cessairement celles de mon employeur._

**Table des mati√®res**
[[toc]]

Si vous souhaitez encourager les analystes de donn√©es et les gestionnaires de donn√©es √† participer au d√©veloppement de pipelines de donn√©es, vous devez vous assurer que chaque commit est test√© et valid√© avant d'√™tre d√©ploy√© en production. Vous voulez √©galement automatiser les t√¢ches r√©p√©titives pour r√©duire la barri√®re technique autant que possible. De plus, vous voulez mettre en place un syst√®me d'observabilit√© solide pour surveiller la sant√© de vos syst√®mes et pipelines de donn√©es et d√©tecter les probl√®mes rapidement.

Pour expliquer comment nous automatisons le d√©ploiement des pipelines de donn√©es, je vais d'abord d√©crire l'architecture de notre plateforme de donn√©es.

## üèóÔ∏è Architecture technique de notre plateforme de donn√©es

Notre pile est actuellement bas√©e sur les composants suivants :

- **Dagster** : L'orchestrateur de nos pipelines de donn√©es. Il nous permet de d√©finir, planifier et surveiller nos workflows de donn√©es.
- **dbt-core** : L'outil de transformation de donn√©es qui nous permet de d√©finir nos mod√®les et transformations de donn√©es de mani√®re modulaire. Il est utilis√© pour construire les mod√®les et transformations de donn√©es qui sont ex√©cut√©s par Dagster.
- **DuckDB** : Le moteur SQL qui nous permet d'ex√©cuter des requ√™tes SQL sur nos donn√©es. Il est utilis√© pour le d√©veloppement et les tests locaux de nos pipelines de donn√©es.
- **Azure** : Le fournisseur cloud qui h√©berge notre plateforme de donn√©es. Nous utilisons Azure Data Lake Storage (ADLS) pour le stockage des donn√©es.
- **Docker** : La technologie de conteneurisation qui nous permet d'empaqueter nos pipelines de donn√©es et leurs d√©pendances de mani√®re portable.
- **GitLab** : Le syst√®me de contr√¥le de version qui nous permet de g√©rer nos d√©p√¥ts de code et d'automatiser nos pipelines CI/CD.

<ImageCenter src="https://raw.githubusercontent.com/tintamarre/tintamarre.github.io/refs/heads/master/src/assets/diagrams/data_platform.drawio.png" alt="Flux de donn√©es dans notre pile" width="600" />

Une remarque importante ici : nos choix techniques ne sont pas grav√©s dans le marbre. Nous √©valuons constamment de nouvelles technologies et approches pour am√©liorer notre plateforme de donn√©es. L'objectif est de fournir une architecture flexible et √©volutive qui peut s'adapter aux besoins changeants de l'organisation. Si `dbt-core`, `Dagster`, ou tout autre outil/fournisseur ne r√©pond plus √† nos besoins, nous n'h√©siterons pas √† le changer. Ce √† quoi nous nous engageons vraiment, c'est l'(1) **architecture**, et les (2) **langages** que nous utilisons pour l'impl√©menter (Python, SQL). Les outils et fournisseurs ne sont que des moyens pour atteindre un objectif.

Pour d'excellentes recommandations sur la fa√ßon de construire une plateforme de donn√©es solide, je recommande de lire [Fundamentals of Data Engineering](https://www.oreilly.com/library/view/fundamentals-of-data/9781098108298/) de Joe Reis et Matt Housley.

### Structure des emplacements de code

Pour permettre √† chaque administration g√©n√©rale (AG) de poss√©der son propre d√©p√¥t (un **code location** dans le vocabulaire Dagster)‚Äîqui contient l'emplacement de code Dagster pour les pipelines de donn√©es de cette AG‚Äînous avons d√©cid√© de **refl√©ter la structure organisationnelle de la FWB dans l'architecture de notre plateforme de donn√©es**. Nous utilisons √©galement des emplacements de code distincts pour des projets sp√©cifiques qui ne sont pas li√©s √† une AG sp√©cifique.
Cela permet √† chaque AG de g√©rer ses propres pipelines de donn√©es de mani√®re ind√©pendante et d'avoir une propri√©t√© claire du code. Les emplacements de code sont ensuite agr√©g√©s dans une seule instance Dagster, qui est la plateforme de donn√©es.

#### üóÇÔ∏è Structure de notre dossier d'emplacements de code

```bash
dagster_home (main) $ tree -L 1
.
‚îú‚îÄ‚îÄ ags_project
‚îú‚îÄ‚îÄ agaj_project
...
‚îú‚îÄ‚îÄ data_platform # notre emplacement de code g√©n√©rique
‚îú‚îÄ‚îÄ dagster.yaml
‚îî‚îÄ‚îÄ workspace.yaml
```

## ü§ñ Automatiser le CI/CD

### Flux CI/CD

Notre configuration de d√©ploiement est bas√©e sur les pipelines GitLab CI/CD. Le flux est le suivant :

0. **Int√©gration des sous-modules** : Les projets DBT sont int√©gr√©s comme un sous-module Git dans le d√©p√¥t principal. Cela nous permet d'inclure le travail des gestionnaires de donn√©es et des analystes dans la plateforme de donn√©es sans avoir √† dupliquer le code ou √† maintenir des d√©p√¥ts s√©par√©s.
1. **Build** : Le code est construit et empaquet√© dans une image Docker ; la m√™me image est utilis√©e pour le Webserver, le Daemon et les emplacements de code.
2. **Valider les d√©finitions** : Les d√©finitions Dagster sont valid√©es pour s'assurer qu'elles sont correctes et ne contiennent aucune erreur.
3. **Ruff** : Le code est v√©rifi√© pour les probl√®mes de style et de formatage √† l'aide de [Ruff](https://docs.astral.sh/ruff/).
4. **Sonar** : Le code est analys√© pour les probl√®mes de qualit√© et de s√©curit√© √† l'aide de [SonarQube](https://www.sonarqube.org/).
5. **Test** : Le code est test√© √† l'aide de [pytest](https://docs.pytest.org/en/stable/) pour les tests unitaires, les tests d'int√©gration et l'analyse de couverture.
6. **D√©ployer en DEV** : Le code est d√©ploy√© dans l'environnement de d√©veloppement pour chaque commit dans la branche principale ou une branche de fonctionnalit√©.
7. **D√©ployer en STAGING** : Lorsqu'un tag est cr√©√©, le code est d√©ploy√© dans l'environnement de staging.
8. **D√©ployer en PROD** : Le code est d√©ploy√© dans l'environnement de production apr√®s validation manuelle en staging.

### √âtapes CI/CD de notre plateforme de donn√©es

```yaml
# .gitlab-ci.yml (simplifi√©)
build: // [!code focus]
  stage: build
  script:
    - docker compose build

validate: // [!code focus]
  stage: test
  script:
    - dagster definitions validate -m data_platform

test: // [!code focus]
  stage: test
  script:
    - pytest -v
      --cov=. --cov-branch --cov-report=html --cov-report=term
      --cov-report xml:coverage.xml
      --junitxml=report.xml

ruff: // [!code focus]
  stage: test
  script:
    - ruff check --output-format=gitlab .

sonarqube-check: // [!code focus]
  stage: test
  script:
    - sonar-scanner

deploy_dev: // [!code focus]
  stage: deploy
  only:
    - main
  script:
    - docker compose up -d

deploy_staging: // [!code focus]
  stage: deploy
  only:
    - tags
  script:
    - docker compose up -d

deploy_prod: // [!code focus]
  stage: deploy
  when: manual
  only:
    - tags
  script:
    - docker compose up -d
```

### Sp√©cificit√©s des environnements

Les environnements sont configur√©s dans le fichier `docker-compose.yml` √† l'aide de variables d'environnement. Chaque environnement a ses propres variables d'environnement, qui sont utilis√©es pour configurer le comportement de la plateforme de donn√©es.

Nous utilisons un seul fichier `docker-compose.yml` dont le contenu peut √™tre adapt√© en fonction de l'environnement. Le fichier compose contient tous les services n√©cessaires pour ex√©cuter la plateforme de donn√©es, y compris le webserver Dagster, le daemon Dagster et les emplacements de code Dagster.

Dans l'exemple suivant, nous montrons comment nous utilisons le m√™me fichier compose pour d√©ployer la plateforme de donn√©es dans diff√©rents environnements en utilisant uniquement des variables d'environnement :

```yaml
# docker-compose.yml (simplifi√©)
version: "3.8"
services:
  dagster_webserver:
    build:
      context: .
    image: ${DOCKER_IMAGE}:${CI_COMMIT_SHORT_SHA}
    restart: unless-stopped
    env_file: .env
    environment:
      - ENVIRONMENT=${ENVIRONMENT} # staging, prod
```

## ü§ñ Automatiser les tests

Tous nos tests sont impl√©ment√©s en Python √† l'aide de `pytest`. Nous couvrons les tests unitaires, les tests d'int√©gration et l'analyse de couverture. Cependant, nous testons g√©n√©ralement seulement les parties critiques de notre code, telles que les d√©finitions Dagster, les ressources personnalis√©es, le code Python et le parsing DBT. Nous ne testons g√©n√©ralement pas les requ√™tes SQL √† moins qu'elles ne contiennent une logique complexe.

## üöÄ Automatiser le d√©ploiement

### Cycle de d√©ploiement de notre plateforme de donn√©es

Le cycle de d√©ploiement de notre plateforme de donn√©es consiste en les √©tapes suivantes :

0. D√©veloppement local ‚Üí un d√©veloppeur travaille sur une nouvelle fonctionnalit√© dans son environnement local.
1. Commit ‚Üí le d√©veloppeur valide ses modifications dans la branche principale ou une branche de fonctionnalit√©.
2. Build ‚Üí GitLab CI/CD construit le code et l'empaquette dans une image Docker.
3. Test ‚Üí GitLab CI/CD ex√©cute les tests et g√©n√®re un rapport de couverture.
4. D√©ployer en DEV ‚Üí GitLab CI/CD d√©ploie le code dans l'environnement de d√©veloppement.
5. Tag de version ‚Üí lorsque le d√©veloppeur est satisfait des modifications, il cr√©e un tag de version.
6. D√©ployer en STAGING ‚Üí GitLab CI/CD d√©ploie le code dans l'environnement de staging.
7. D√©ployer en PROD ‚Üí Apr√®s validation en staging, GitLab CI/CD d√©ploie le code dans l'environnement de production.

<ImageCenter src="https://raw.githubusercontent.com/tintamarre/tintamarre.github.io/refs/heads/master/src/assets/diagrams/dagster_code_location_cycle.drawio.png" alt="Cycle de d√©ploiement de l'emplacement de code Dagster" width="600" />

### Cycle de d√©ploiement de nos projets DBT

Lorsqu'une nouvelle version est cr√©√©e, le projet DBT est automatiquement versionn√© √† l'aide de l'outil `release`. La version est incr√©ment√©e et un changelog est g√©n√©r√©. Le projet DBT est ensuite analys√© √† l'aide de `dbt parse` pour produire le fichier `manifest.json`, qui contient les m√©tadonn√©es du projet DBT. Ce fichier est utilis√© par Dagster pour d√©couvrir les mod√®les DBT et leurs d√©pendances.

#### Le cycle de version de nos projets DBT consiste en les √©tapes suivantes :

```yaml
# .gitlab-ci.yml
sqlfluff: // [!code focus]
  allow_failure: true
  script:
    - sqlfluff lint models

release: // [!code focus]
  script:
    - VERSION=$(release next-version)
    - |
      sed -i "s/version: \"[^\"]*\"/version: \"$VERSION\"/" "$FILETOCHANGE"
    - release changelog
    - release commit-and-tag --create-tag-pipeline CHANGELOG.md ${DBT_PATH}/dbt_project.yml // [!code focus]

dagster_submodule: // [!code focus]
  rules:
    - if: "$CI_COMMIT_TAG"
  script:
    [...]
    - git add .
    - git diff --cached --quiet || git commit -m "Update dbt submodule"  // [!code focus]
    # Pousser les modifications sans forcer la suppression
    - git push origin dagster_submodule // [!code focus]

# Cette √©tape publie un artefact pour la documentation DBT.
pages: // [!code focus]
  stage: dbt_docs
  only:
    - main
  script:
    [...]
    - dbt docs generate // [!code focus]
```

## üëÄ Automatiser l'observabilit√©

L'observabilit√© de notre plateforme de donn√©es est un aspect cl√© de la mise en ≈ìuvre d'une Plateforme de Donn√©es. Elle nous permet de surveiller la sant√© de nos syst√®mes (1) et de nos pipelines de donn√©es (2), de d√©tecter les probl√®mes rapidement et d'assurer la qualit√© de nos donn√©es (3).

<ImageCenter src="https://raw.githubusercontent.com/tintamarre/tintamarre.github.io/refs/heads/master/src/assets/images/ms-team-panopticon.png" alt="Panopticon" width="600" />

### Observabilit√© de notre pile (conteneurs)

Pour l'observabilit√© de nos syst√®mes, nous utilisons [Kibana](https://www.elastic.co/kibana) et [Dozzle](https://dozzle.dev/) pour surveiller les journaux et les m√©triques de notre plateforme de donn√©es.

### Observabilit√© de nos pipelines de donn√©es

Comme un [panopticon](https://fr.wikipedia.org/wiki/Panoptique) ou un **hub d'observabilit√© centralis√©**, nous utilisons principalement un canal MS Teams (accessible par toutes les parties prenantes) pour centraliser l'observabilit√© de notre plateforme de donn√©es en un seul endroit. Certaines notifications personnalis√©es sont √©galement envoy√©es via NTFY et Email pour des √©v√©nements ou alertes sp√©cifiques.

### Observabilit√© de nos donn√©es

Pour l'observabilit√© de nos donn√©es, nous utilisons les fonctionnalit√©s int√©gr√©es de Dagster pour v√©rifier la qualit√© de nos donn√©es. Dagster fournit un ensemble de fonctionnalit√©s d'observabilit√© (personnalis√©es ou int√©gr√©es) qui nous permettent de surveiller la sant√© de nos pipelines de donn√©es et de d√©tecter les probl√®mes rapidement.

M√™me sans √©crire de v√©rifications personnalis√©es, l'interface utilisateur de Dagster nous permet de surveiller la qualit√© de nos donn√©es. Voici comment nous avons trouv√© un probl√®me de qualit√© dans l'un de nos pipelines de donn√©es :

<ImageCenter src="https://raw.githubusercontent.com/tintamarre/tintamarre.github.io/refs/heads/master/src/assets/images/dagster_asset_quality.png" alt="Comment la fonctionnalit√© d'observabilit√© nous a aid√©s √† d√©tecter des probl√®mes de qualit√©" width="600" />

---

Dans cet article, nous avons explor√© comment automatiser le d√©ploiement de pipelines de donn√©es dans une organisation polyc√©phale comme la FWB. Nous avons vu comment utiliser Dagster comme orchestrateur, dbt-core pour les transformations de donn√©es, et GitLab CI/CD pour automatiser le processus de d√©ploiement.

Nous avons √©galement discut√© de l'importance de la **modularit√©** et de la **r√©utilisabilit√©** des composants pour abaisser la barri√®re technique pour les analystes de donn√©es et les gestionnaires de donn√©es. En automatisant le processus de d√©ploiement, nous pouvons nous assurer que chaque commit est test√© et valid√© avant d'√™tre d√©ploy√© en production, ce qui encourage la participation des analystes de donn√©es et des gestionnaires de donn√©es dans le d√©veloppement de pipelines de donn√©es.

Mais comme indiqu√© dans l'introduction, le **niveau de participation est inversement proportionnel √† la barri√®re technique**. Plus la configuration est complexe, moins les analystes de donn√©es et les gestionnaires de donn√©es sont susceptibles de participer au d√©veloppement de pipelines de donn√©es.

Dans le prochain article, nous explorerons comment abaisser encore davantage la barri√®re technique en fournissant des ressources conviviales pour que les professionnels des donn√©es interagissent avec la plateforme de donn√©es. Nous discuterons √©galement de la fa√ßon d'am√©liorer la litt√©ratie des donn√©es parmi les analystes de donn√©es et les gestionnaires de donn√©es pour les encourager √† participer au d√©veloppement de pipelines de donn√©es.

- [Partie 3 : Comment les ressources personnalis√©es et la formation aident √† abaisser la barri√®re](/blog/posts/2025/data_platform_in_fwb_02_lower_barrier-fr)
